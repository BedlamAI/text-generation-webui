{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0c2b47",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "from lancedb.embeddings import with_embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d2340",
   "metadata": {},
   "source": [
    "### Inference and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c459b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_func(batch):\n",
    "    # sentence must be string, and not None\n",
    "    return [model.encode(sentence) for sentence in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb83657",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced801a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename=\"all_in_one_jigsaw.csv\"):\n",
    "    print (\"Loading data from\", filename)\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    # type to string\n",
    "    df[\"id\"] = df.id.apply(lambda s: str_or_empty(s))\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to type these to strings for LanceDB\n",
    "def str_or_empty(val):\n",
    "    try:\n",
    "        return str(val)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# load the small sentence transformer model\n",
    "def load_transformer_model(name=\"paraphrase-albert-small-v2\"):\n",
    "    print (\"Loading transformer model\", name)\n",
    "    model = SentenceTransformer(name)\n",
    "    return model\n",
    "\n",
    "# this returns a pyarrow Table with the original data + a new vector column\n",
    "# pass in the first 1000 rows for the sake of time\n",
    "def create_embeddings(\n",
    "        df, \n",
    "        func=embed_func, \n",
    "        row_limit=1000, \n",
    "        show_progress=True):\n",
    "    print (\"Creating embeddings with row_limit\", row_limit)\n",
    "    data = with_embeddings(func, df[:row_limit], column=\"comment_text\",\n",
    "                           wrap_api=False, batch_size=100, show_progress=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "# data is the output of create_embeddings\n",
    "def create_lancedb_table(\n",
    "        data, \n",
    "        uri=\"~/.lancedb\", \n",
    "        name=\"jigsaw\", \n",
    "        index_table=True, \n",
    "        num_partitions=4):\n",
    "    print (\"creating lancedb table\", name)\n",
    "    db = lancedb.connect(uri)\n",
    "    tbl = db.create_table(name, data, )\n",
    "    # depending on function inputs\n",
    "    if index_table:\n",
    "        print (\"indexing table with num_partitions\", num_partitions)\n",
    "        tbl.create_index(\n",
    "            num_partitions=num_partitions, \n",
    "            num_sub_vectors=num_partitions)\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15c8b7",
   "metadata": {},
   "source": [
    "### Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_lancedb_table(uri=\"~/.lancedb\", name=\"jigsaw\"):\n",
    "    db = lancedb.connect(uri)\n",
    "    tbl = db.open_table(name)\n",
    "    return tbl\n",
    "\n",
    "def run_query(tbl, query, topk=5):\n",
    "    emb = embed_func([query])[0]\n",
    "    return tbl.search(emb).limit(topk).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8c579",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4be9b",
   "metadata": {},
   "source": [
    "##### prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(filename=\"../all_in_one_jigsaw.csv\")\n",
    "model=load_transformer_model(name=\"paraphrase-albert-small-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a2429",
   "metadata": {},
   "source": [
    "#### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jigsaw data should be located in the main folder\n",
    "data = create_embeddings(df, row_limit=1000000)\n",
    "tbl = create_lancedb_table(data, uri=\"~/.lancedb\", name=\"jigsaw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f10e04",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = connect_lancedb_table(uri=\"~/.lancedb\", name=\"jigsaw\")\n",
    "\n",
    "query=\"this is an insult about your mother\"\n",
    "\n",
    "df=run_query(tbl, query, topk=5)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527ce56",
   "metadata": {},
   "source": [
    "### Moderate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ef38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderation_scores(df): \n",
    "    moderation_dict={\n",
    "        \"toxic\":df[\"toxic\"].mean(),\n",
    "        \"obscene\":df[\"obscene\"].mean(),\n",
    "        \"threat\":df[\"threat\"].mean(),\n",
    "        \"insult\":df[\"insult\"].mean(),\n",
    "        \"identity_hate\":df[\"identity_hate\"].mean()\n",
    "    }\n",
    "    return moderation_dict;\n",
    "\n",
    "def assess_prompt(moderation_json, global_cutoff=0.5):\n",
    "    '''\n",
    "    returns (accept_prompt True/False, reasons for rejected if rejected)\n",
    "        True if accepted, False if not accepted\n",
    "        If True, array of reasons for rejected is empty\n",
    "    '''\n",
    "    prompt_rejected_reasons=[]\n",
    "    for key, value in moderation_json.items():\n",
    "        if value > global_cutoff:\n",
    "            prompt_rejected_reasons.append(key)\n",
    "    # rejected\n",
    "    if len(prompt_rejected_reasons)==0:\n",
    "        return True, prompt_rejected_reasons\n",
    "    else:\n",
    "        return False, prompt_rejected_reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderation_dict = moderation_scores(df)\n",
    "accept_prompt, prompt_rejection_reasons = assess_prompt(moderation_dict)\n",
    "\n",
    "print ('Accept Prompt?', accept_prompt)\n",
    "if not accept_prompt:\n",
    "    for reason in prompt_rejection_reasons:\n",
    "        print (reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d63a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
